<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>GPU Acceleration Test - WebAssembly Demo</title>
    <link rel="stylesheet" href="styles.css">
    <!-- Favicon configuration -->
    <link rel="icon" type="image/png" href="media/favicon/favicon-32x32.png">
    <!-- JetBrains Mono font -->
    <style>
        @font-face {
            font-family: 'JetBrains Mono';
            src: url('media/fonts/JetBrainsMono-Regular.ttf') format('truetype');
            font-weight: normal;
            font-style: normal;
        }
    </style>
</head>
<body>
    <header>
        <nav class="navbar">
            <a href="index.html" class="logo">Jack ten Bosch</a>
            <div class="nav-links">
                <a href="blogs.html">blog</a> <a href="projects.html">projects</a> <a href="photography.html">photography</a>
            </div>
        </nav>
        <hr class="nav-divider">
    </header>

    <main>
        <h1>GPU Acceleration Test - WebAssembly Demo</h1>

        <p><a href="https://github.com/gojack10/gpu-acceleration-test">View on GitHub</a></p>

        <p>This project demonstrates GPU acceleration using modern graphics APIs, implemented in Rust. It features two branches: the <strong>main branch</strong> for native desktop applications and the <strong>web-integration branch</strong> for browser-based WebAssembly deployment.</p>
        
        <div id="canvas-container" style="width: 100%; height: 500px; position: relative; margin: 20px 0;">
            <canvas id="canvas" style="width: 100%; height: 100%; border: 1px solid #555; display: block;"></canvas>
        </div>
        
        <div id="status" style="margin-top: 20px; padding: 10px; background-color: rgba(255, 255, 255, 0.1); border-radius: 4px; font-family: 'JetBrains Mono', monospace; font-size: 0.85rem;">Status: Loading WebAssembly module...</div>

        <h2>GPU Acceleration in Rust: From Desktop to Web with WebAssembly</h2>

        <p>Modern graphics programming has evolved significantly, with GPU acceleration becoming essential for high-performance applications. This project demonstrates GPU acceleration using Rust and how it can be adapted to run in web browsers through WebAssembly.</p>

        <h2>The Main Branch: Native GPU Acceleration</h2>

        <p>The main branch is a native desktop application that leverages hardware-accelerated graphics through the wgpu library, providing maximum performance by directly accessing the system's GPU capabilities.</p>

        <pre><code class="language-rust">// From temp_gpu_project/main-branch/src/lib.rs
pub mod texture;
pub mod vertex;
pub mod render_device;
pub mod system_info;
pub mod state;
pub mod debug;
pub mod device_selector;</code></pre>

        <p>Key components include the application entry point, rendering pipeline, geometry definitions, shaders, debug overlay, and device selection for CPU/GPU rendering.</p>

        <h2>Project Overview</h2>

        <h3>Web Integration Branch</h3>
        <p>The web-integration branch extends the core rendering engine to work in web browsers through WebAssembly, allowing GPU-accelerated rendering to run directly in modern browsers without plugins.</p>

        <h4>Technical Stack:</h4>
        <ul>
            <li><strong>Graphics API:</strong> WebGPU/WebGL via wgpu</li>
            <li><strong>WebAssembly:</strong> wasm-bindgen, wasm-pack</li>
            <li><strong>JavaScript:</strong> web-sys, js-sys</li>
            <li><strong>Shader:</strong> WGSL (WebGPU Shading Language)</li>
        </ul>

        <p>The web integration uses conditional compilation to separate platform-specific code:</p>
        <pre><code>#[cfg(target_arch = "wasm32")]
// Web-specific code

#[cfg(not(target_arch = "wasm32"))]
// Desktop-specific code</code></pre>

        <p>Web-specific features include canvas integration, WebGL context management, and browser event handling.</p>

        <h3>Main Branch (Desktop)</h3>
        <p>The main branch focuses on native desktop performance, using platform-specific graphics APIs for maximum efficiency.</p>

        <h4>Technical Stack:</h4>
        <ul>
            <li><strong>Graphics API:</strong> wgpu (abstracting over Vulkan, Metal, DirectX)</li>
            <li><strong>Window Management:</strong> winit</li>
            <li><strong>UI Framework:</strong> egui (for debug overlays)</li>
            <li><strong>System Information:</strong> sysinfo</li>
        </ul>

        <p>The desktop version includes hardware-specific optimizations, detailed system information, and an interactive debug overlay.</p>

        <h2>How It Works</h2>

        <p>Both versions share the same core rendering pipeline:</p>
        <ol>
            <li>Initialize the graphics context (WebGL for web, native API for desktop)</li>
            <li>Create shader programs using WGSL</li>
            <li>Set up vertex and index buffers for 3D geometry</li>
            <li>Create texture resources</li>
            <li>Implement a render loop with transformation matrices</li>
            <li>Display performance metrics</li>
        </ol>

        <p>The web version compiles to WebAssembly and interfaces with WebGL, while the desktop version compiles to native code and interfaces directly with graphics drivers.</p>

        <h3>Shared Components</h3>

        <p>Both branches share several key components:</p>

        <h4>1. Vertex Definitions</h4>

        <pre><code class="language-rust">// From vertex.rs
#[repr(C)]
#[derive(Copy, Clone, Debug, bytemuck::Pod, bytemuck::Zeroable)]
pub struct Vertex {
    pub position: [f32; 3],
    pub tex_coords: [f32; 2],
    pub normal: [f32; 3],
}</code></pre>

        <h4>2. Render Device Abstraction</h4>

        <pre><code class="language-rust">// From render_device.rs
#[derive(Clone, Debug, PartialEq)]
pub enum RenderDevice {
    CPU,
    GPU(String),
}</code></pre>

        <h4>3. Transformation Logic</h4>

        <pre><code class="language-rust">// Create matrices for 3D rendering
let projection = Mat4::perspective_rh(45.0 * (PI / 180.0), aspect, 0.1, 100.0);
let view = Mat4::look_at_rh(
    Vec3::new(0.0, 0.0, 3.0), // Camera position
    Vec3::new(0.0, 0.0, 0.0), // Look at origin
    Vec3::new(0.0, 1.0, 0.0), // Up vector
);</code></pre>

        <h2>Browser Compatibility</h2>
        <p>The web version requires a browser with WebGL 2 support:</p>
        <ul>
            <li>Chrome/Edge (version 79+)</li>
            <li>Firefox (version 71+)</li>
            <li>Safari (version 15+)</li>
        </ul>
        <p>A dedicated GPU is recommended for optimal performance.</p>

        <h2>Deep Dive: Main Branch Architecture</h2>
        
        <p>The main branch leverages hardware-accelerated graphics through wgpu, with these key components:</p>
        
        <ul>
            <li><strong>Rendering Pipeline:</strong> Manages GPU resources and shader execution</li>
            <li><strong>3D Geometry:</strong> Defines vertices with positions, texture coordinates, and normals</li>
            <li><strong>Transformation:</strong> Uses matrix math for model-view-projection transformations</li>
            <li><strong>Debug Overlay:</strong> Provides real-time performance metrics</li>
            <li><strong>Device Selection:</strong> Allows choosing between CPU and GPU rendering</li>
        </ul>

        <h3>Initialization Process</h3>

        <pre><code class="language-rust">// Main application initialization
fn main() -> Result<()> {
    // Create wgpu instance
    let instance = wgpu::Instance::new(wgpu::InstanceDescriptor {
        backends: wgpu::Backends::all(),
        ..Default::default()
    });
    
    // Get system info and select rendering device
    let mut system_info = get_system_info(&instance);
    let render_device = prompt_device_selection(&mut system_info);
    
    // Create and run the application
    let event_loop = EventLoop::new().unwrap();
    event_loop.run_app(&mut App { /* ... */ })?;
    Ok(())
}</code></pre>

        <h3>Shader Implementation</h3>
        
        <p>The application uses WGSL (WebGPU Shading Language) for its shaders:</p>

        <pre><code class="language-wgsl">// Vertex shader
struct VertexInput {
    @location(0) position: vec3<f32>,
    @location(1) tex_coords: vec2<f32>,
    @location(2) normal: vec3<f32>,
};

@vertex
fn vs_main(model: VertexInput) -> VertexOutput {
    var out: VertexOutput;
    out.tex_coords = model.tex_coords;
    out.clip_position = uniforms.model_view_proj * vec4<f32>(model.position, 1.0);
    out.normal = model.normal;
    return out;
}

// Fragment shader
@fragment
fn fs_main(in: VertexOutput) -> @location(0) vec4<f32> {
    return textureSample(t_diffuse, s_diffuse, in.tex_coords);
}</code></pre>

        <h3>3D Geometry and Animation</h3>
        
        <p>The application renders a textured 3D cube with position, texture coordinates, and normal vectors. The cube rotates continuously, with transformation matrices handling the 3D perspective and camera positioning.</p>

        <h3>Debug Overlay</h3>
        
        <p>The application includes a comprehensive debug overlay implemented with egui:</p>
        
        <ul>
            <li>Displays real-time FPS and frame time metrics</li>
            <li>Shows CPU and GPU information</li>
            <li>Provides details about the rendering pipeline</li>
            <li>Includes visualization of coordinate axes</li>
            <li>Can be toggled on/off with the F1 key</li>
        </ul>

        <h3>Input Handling</h3>
        
        <p>User input is processed in the <code>State::input()</code> method:</p>
        
        <ul>
            <li>Keyboard events for toggling debug overlay (F1)</li>
            <li>Window resize events to update the rendering surface</li>
            <li>Mouse events for potential camera control (not fully implemented)</li>
        </ul>

        <h3>Performance Optimization</h3>
        
        <p>The application includes several performance optimizations:</p>
        
        <ul>
            <li>Indexed drawing to reduce vertex data</li>
            <li>Depth buffering for correct 3D rendering</li>
            <li>Efficient uniform buffer updates</li>
            <li>Hardware-specific adapter selection</li>
            <li>Frame time tracking for performance monitoring</li>
        </ul>

        <h3>Device Selection</h3>
        
        <p>The application allows choosing between CPU and GPU rendering:</p>
        
        <ul>
            <li>The <code>RenderDevice</code> enum represents either CPU or GPU rendering</li>
            <li>The <code>prompt_device_selection()</code> function displays available devices and lets the user choose</li>
            <li>The selected device affects adapter selection in the initialization process</li>
            <li>This allows testing performance differences between software and hardware rendering</li>
        </ul>

        <h3>Technical Challenges</h3>
        
        <p>The main branch addresses several technical challenges:</p>
        
        <ul>
            <li><strong>Cross-Platform Rendering</strong>: Using wgpu to abstract over different graphics APIs (Vulkan, Metal, DirectX)</li>
            <li><strong>Hardware Detection</strong>: Identifying and selecting appropriate rendering devices</li>
            <li><strong>Performance Monitoring</strong>: Implementing real-time metrics for GPU and CPU usage</li>
            <li><strong>3D Mathematics</strong>: Handling transformation matrices and 3D geometry</li>
            <li><strong>Resource Management</strong>: Properly creating and destroying GPU resources</li>
        </ul>

        <h3>Code Structure</h3>
        
        <p>The codebase is organized into modular components:</p>
        
        <ul>
            <li><strong>main.rs</strong>: Application entry point and event loop</li>
            <li><strong>state.rs</strong>: Core rendering state and pipeline management</li>
            <li><strong>vertex.rs</strong>: Vertex definitions and geometry creation</li>
            <li><strong>texture.rs</strong>: Texture loading and management</li>
            <li><strong>shader.wgsl</strong>: GPU shader code</li>
            <li><strong>debug.rs</strong>: Debug overlay and performance monitoring</li>
            <li><strong>system_info.rs</strong>: Hardware detection and information</li>
            <li><strong>device_selector.rs</strong>: User interface for device selection</li>
            <li><strong>render_device.rs</strong>: Abstraction for rendering devices</li>
        </ul>

        <p>This modular approach makes the code maintainable and extensible, allowing for easy addition of new features or optimization of existing ones.</p>

        <h2>Deep Dive: Web Integration Architecture</h2>
        
        <p>The web-integration branch adapts the core architecture to run in browsers through WebAssembly:</p>

        <h3>WebAssembly Integration</h3>
        
        <pre><code class="language-rust">// Web-specific module
#[cfg(target_arch = "wasm32")]
pub mod web;

// Exposed functions for JavaScript
#[wasm_bindgen]
pub fn init() {
    init_logging();
}

#[wasm_bindgen]
pub async fn initialize(canvas: HtmlCanvasElement) -> Result<bool, JsValue> {
    // Initialize WebGL context
}

#[wasm_bindgen]
pub fn start_render_loop() -> Result<(), JsValue> {
    // Start animation frame loop
}</code></pre>

        <h3>WebGL Rendering Pipeline</h3>
        
        <p>The web version adapts the main branch's rendering pipeline to use WebGL 2:</p>
        
        <ul>
            <li>GLSL ES 3.0 shaders converted from the main branch's WGSL</li>
            <li>WebGL buffer objects for geometry data</li>
            <li>Uniform variables for transformations</li>
            <li>Browser's requestAnimationFrame for timing</li>
        </ul>

        <h3>Key Differences Between Branches</h3>

        <h4>1. Graphics API</h4>
        <ul>
            <li><strong>Main Branch:</strong> Uses native backends (Vulkan, Metal, DirectX)</li>
            <li><strong>Web Branch:</strong> Uses WebGL 2 with browser limitations</li>
        </ul>

        <h4>2. Rendering Architecture</h4>
        <ul>
            <li><strong>Main Branch:</strong> Uses WGSL shaders and native rendering pipeline</li>
            <li><strong>Web Branch:</strong> Uses GLSL ES 3.0 shaders and WebGL pipeline</li>
        </ul>

        <h4>3. Platform Integration</h4>
        <ul>
            <li><strong>Main Branch:</strong> Interfaces with native window system and event handling</li>
            <li><strong>Web Branch:</strong> Interfaces with browser DOM and requestAnimationFrame</li>
        </ul>

        <h4>4. Build System</h4>
        <ul>
            <li><strong>Main Branch:</strong> Standard Cargo build for native binaries</li>
            <li><strong>Web Branch:</strong> wasm-pack for WebAssembly compilation</li>
        </ul>

        <p>The codebase uses conditional compilation to handle these differences:</p>
        
        <pre><code class="language-rust">#[cfg(target_arch = "wasm32")]
// Web-specific code

#[cfg(not(target_arch = "wasm32"))]
// Desktop-specific code</code></pre>

        <h2>Conclusion</h2>

        <p>This project demonstrates how modern Rust can be used to create high-performance graphics applications that run both natively and on the web. By leveraging WebAssembly, the same core rendering logic works across platforms with minimal adaptation.</p>
        
        <p>Key takeaways:</p>
        <ul>
            <li>Rust provides excellent tools for cross-platform graphics development</li>
            <li>WebAssembly enables high-performance web applications with near-native speed</li>
            <li>Conditional compilation allows targeting multiple platforms from a single codebase</li>
            <li>Modern graphics APIs like wgpu provide abstraction over platform-specific details</li>
        </ul>
        
        <p>Whether you're building desktop applications or web experiences, this architecture offers a solid foundation for GPU-accelerated graphics in Rust.</p>
    </main>
    <button id="scroll-top" aria-label="Scroll to top">^</button>
    <script>
      const scrollButton = document.getElementById('scroll-top');
      
      window.addEventListener('scroll', () => {
        if (window.pageYOffset > 300) {
          scrollButton.classList.add('visible');
        } else {
          scrollButton.classList.remove('visible');
        }
      });
      
      scrollButton.addEventListener('click', () => {
        window.scrollTo({
          top: 0,
          behavior: 'smooth'
        });
      });
    </script>
    <!-- WebAssembly Module Initialization -->
    <script type="module">
        // Set the path to the WebAssembly module
        const wasmPath = './demos/gpu-acceleration/pkg/gpu_acceleration_test_bg.wasm';
        
        // Import the JavaScript module
        import init, { initialize, start_render_loop } from './demos/gpu-acceleration/pkg/gpu_acceleration_test.js';

        // Known texture names to pre-load
        const TEXTURE_NAMES = ["block.png", "cube-diffuse.jpg", "texture.png"];
        
        // Embedded fallback texture (simple colored checkerboard pattern)
        const BASE64_TEXTURE = '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';

        /**
         * Advanced texture handling strategy:
         * 
         * 1. Create texture objects for known texture names
         * 2. Modify WebAssembly.instantiate to patch all imports related to textures
         * 3. Intercept ALL possible network requests at multiple levels
         * 4. Provide global texture accessor functions
         */
        
        // Create a blob URL from base64 data
        function createBlobUrl(base64Data) {
            try {
                // Convert base64 to binary
                const binaryString = atob(base64Data);
                const bytes = new Uint8Array(binaryString.length);
                for (let i = 0; i < binaryString.length; i++) {
                    bytes[i] = binaryString.charCodeAt(i);
                }
                
                // Create a blob and URL
                const blob = new Blob([bytes], { type: 'image/png' });
                return URL.createObjectURL(blob);
            } catch (e) {
                console.error('Error creating blob URL:', e);
                return null;
            }
        }
        
        // Set up texture data and make it globally available
        async function setupTextures() {
            // Create all texture sources
            const blobUrl = createBlobUrl(BASE64_TEXTURE);
            if (!blobUrl) {
                throw new Error('Failed to create blob URL');
            }
            
            // Store texture metadata
            window.textureCache = {};
            window.texturePaths = {};
            window.textureData = null; // Will hold the primary texture data
            
            // Load the image and extract its data
            return new Promise((resolve, reject) => {
                const img = new Image();
                img.onload = () => {
                    // Create a canvas to extract pixel data
                    const canvas = document.createElement('canvas');
                    canvas.width = img.width;
                    canvas.height = img.height;
                    const ctx = canvas.getContext('2d');
                    ctx.drawImage(img, 0, 0);
                    
                    // Extract the image data
                    const imageData = ctx.getImageData(0, 0, img.width, img.height);
                    
                    // Store texture data in multiple formats for different access patterns
                    window.textureData = {
                        data: imageData.data,
                        width: img.width, 
                        height: img.height,
                        url: blobUrl,
                        image: img,
                        canvas: canvas
                    };
                    
                    // Create cache entries for all known texture names
                    TEXTURE_NAMES.forEach(name => {
                        window.textureCache[name] = window.textureData;
                        window.texturePaths[name] = blobUrl;
                        
                        // Also store at common paths the texture might be looked up at
                        const variations = [
                            name,
                            `/${name}`,
                            `./demos/gpu-acceleration/assets/${name}`,
                            `./assets/${name}`,
                            `assets/${name}`,
                            `demos/gpu-acceleration/assets/${name}`
                        ];
                        
                        variations.forEach(path => {
                            window.textureCache[path] = window.textureData;
                            window.texturePaths[path] = blobUrl;
                        });
                    });
                    
                    console.log('Texture setup complete:', window.textureData);
                    resolve(window.textureData);
                };
                
                img.onerror = (err) => {
                    console.error('Error loading texture image:', err);
                    reject(new Error('Failed to load texture image'));
                };
                
                img.src = blobUrl;
            });
        }
        
        // Patch all WebAssembly imports related to textures
        async function patchWasmImports() {
            // Store the original WebAssembly.instantiate methods
            const originalInstantiate = WebAssembly.instantiate;
            const originalInstantiateStreaming = WebAssembly.instantiateStreaming;
            
            // Override instantiate to intercept and modify imports
            WebAssembly.instantiate = async function(bufferSource, importObject) {
                console.log('WebAssembly.instantiate intercepted', importObject);
                
                if (importObject && importObject.env) {
                    // Add our texture functions to the environment
                    importObject.env = {
                        ...importObject.env,
                        
                        // Texture loading function
                        load_texture: function(path_ptr, path_len) {
                            console.log('load_texture called with path_ptr:', path_ptr, 'path_len:', path_len);
                            return window.textureData;
                        },
                        
                        // Texture path function
                        get_texture_path: function() {
                            console.log('get_texture_path called');
                            return window.textureData?.url || '';
                        },
                        
                        // Generic file loading
                        load_file: function(path_ptr, path_len) {
                            console.log('load_file called');
                            return window.textureData;
                        },
                        
                        // Direct JS function to get texture data
                        js_get_texture_data: function() {
                            console.log('js_get_texture_data called');
                            return window.textureData;
                        }
                    };
                }
                
                // Call the original instantiate
                return originalInstantiate.apply(this, arguments);
            };
            
            // Also override instantiateStreaming
            WebAssembly.instantiateStreaming = async function(source, importObject) {
                console.log('WebAssembly.instantiateStreaming intercepted');
                
                // Convert streaming to a buffer first, then use our patched instantiate
                const response = await source;
                const buffer = await response.arrayBuffer();
                return WebAssembly.instantiate(buffer, importObject);
            };
        }
        
        // Intercept all network requests that might load textures
        function interceptNetworkRequests() {
            // 1. Intercept fetch API
            const originalFetch = window.fetch;
            window.fetch = function(resource, options) {
                if (resource && typeof resource === 'string') {
                    console.log(`Fetch intercepted: ${resource}`);
                    
                    // Check if we're fetching a texture
                    const isTextureFetch = TEXTURE_NAMES.some(name => resource.includes(name));
                    if (isTextureFetch) {
                        console.log(`Texture fetch detected: ${resource}`);
                        
                        // Create a response from our cached texture
                        const blob = new Blob(
                            [new Uint8Array(atob(BASE64_TEXTURE).split('').map(c => c.charCodeAt(0)))], 
                            { type: 'image/png' }
                        );
                        
                        return Promise.resolve(new Response(blob, { 
                            status: 200, 
                            headers: { 'Content-Type': 'image/png' }
                        }));
                    }
                }
                
                // Pass through to original fetch for non-texture requests
                return originalFetch.apply(this, arguments);
            };
            
            // 2. Intercept XMLHttpRequest
            const originalOpen = XMLHttpRequest.prototype.open;
            XMLHttpRequest.prototype.open = function(method, url, async, user, password) {
                if (url && typeof url === 'string') {
                    console.log(`XMLHttpRequest.open intercepted: ${url}`);
                    
                    // Check if this is a texture request
                    const isTextureRequest = TEXTURE_NAMES.some(name => url.includes(name));
                    if (isTextureRequest) {
                        console.log(`Texture XHR detected: ${url}`);
                        this._isTextureRequest = true;
                        
                        // Redirect to our blob URL
                        return originalOpen.call(
                            this, 
                            method, 
                            window.textureData.url, 
                            async === undefined ? true : async, 
                            user, 
                            password
                        );
                    }
                }
                
                // Pass through to original open
                return originalOpen.apply(this, arguments);
            };
            
            // 3. Intercept Image loading
            const originalImageSrc = Object.getOwnPropertyDescriptor(HTMLImageElement.prototype, 'src');
            if (originalImageSrc && originalImageSrc.set) {
                Object.defineProperty(HTMLImageElement.prototype, 'src', {
                    set: function(url) {
                        if (url && typeof url === 'string') {
                            console.log(`Image.src intercepted: ${url}`);
                            
                            // Check if this is a texture load
                            const isTextureLoad = TEXTURE_NAMES.some(name => url.includes(name));
                            if (isTextureLoad) {
                                console.log(`Texture image load detected: ${url}`);
                                
                                // Use our texture blob URL instead
                                url = window.textureData.url;
                            }
                        }
                        
                        // Call the original setter
                        originalImageSrc.set.call(this, url);
                    },
                    get: originalImageSrc.get
                });
            }
            
            // 4. Provide global helpers for texture access
            window.getTexturePath = function(name) {
                console.log(`getTexturePath called with: ${name}`);
                return window.texturePaths[name] || window.textureData.url;
            };
            
            window.getTextureData = function(name) {
                console.log(`getTextureData called with: ${name}`);
                return window.textureCache[name] || window.textureData;
            };
            
            window.getTextureElement = function(name) {
                console.log(`getTextureElement called with: ${name}`);
                return window.textureData.image;
            };
            
            // Also attach to window.wasm for direct access
            window.wasm = {
                textureData: function() { return window.textureData; },
                texturePath: function(name) { return window.getTexturePath(name); }
            };
        }
        
        // Main initialization function
        async function initializeApplication() {
            try {
                document.getElementById('status').textContent = 'Status: Setting up texture data...';
                
                // 1. First set up our textures
                await setupTextures();
                document.getElementById('status').textContent = 'Status: Texture data ready.';
                
                // 2. Patch WebAssembly imports to inject our texture handlers
                await patchWasmImports();
                document.getElementById('status').textContent = 'Status: WebAssembly imports patched.';
                
                // 3. Intercept network requests
                interceptNetworkRequests();
                document.getElementById('status').textContent = 'Status: Network interception enabled.';
                
                // 4. Initialize the WASM module with all our preparations
                try {
                    document.getElementById('status').textContent = 'Status: Loading WebAssembly module...';
                    
                    // Initialize with our texture data directly attached
                    // This allows the module to access it via JavaScript imports
                    const initResult = await init(wasmPath);
                    console.log('WASM init result:', initResult);
                    
                    document.getElementById('status').textContent = 'Status: WebAssembly loaded. Setting up canvas...';
                    
                    // Set up the canvas
                    const canvas = document.getElementById('canvas');
                    canvas.width = canvas.clientWidth;
                    canvas.height = canvas.clientHeight;
                    
                    // Modify the initialize function to handle textures
                    const originalInitialize = initialize;
                    window.customInitialize = async function(canvas) {
                        console.log('Custom initialize called with texture data available');
                        
                        // Try to directly inject our texture data
                        try {
                            // Check if it accepts a second parameter for texture data
                            return await originalInitialize(canvas, window.textureData);
                        } catch (e) {
                            console.log('Initialize with texture data failed, trying standard initialize');
                            return await originalInitialize(canvas);
                        }
                    };
                    
                    // Initialize the WebGL context
                    document.getElementById('status').textContent = 'Status: Initializing WebGL...';
                    try {
                        // Call our custom initialize with texture data
                        const result = await window.customInitialize(canvas);
                        console.log('WebGL initialization result:', result);
                        
                        if (result === true) {
                            // Start the render loop
                            document.getElementById('status').textContent = 'Status: WebGL initialized. Starting render loop...';
                            
                            try {
                                start_render_loop();
                                document.getElementById('status').textContent = 'Status: Render loop started successfully!';
                            } catch (e) {
                                console.error('Error starting render loop:', e);
                                document.getElementById('status').textContent = `Status: Error starting render loop: ${e.message || e}`;
                            }
                        } else {
                            document.getElementById('status').textContent = 'Status: WebGL initialization failed.';
                        }
                    } catch (e) {
                        console.error('Error initializing WebGL:', e);
                        document.getElementById('status').textContent = `Status: Error initializing WebGL: ${e.message || e}`;
                    }
                } catch (e) {
                    console.error('Error loading WebAssembly:', e);
                    document.getElementById('status').textContent = `Status: Error loading WebAssembly: ${e.message || e}`;
                }
            } catch (e) {
                console.error('Setup error:', e);
                document.getElementById('status').textContent = `Status: Setup error: ${e.message || e}`;
            }
        }
        
        // Handle window resize
        window.addEventListener('resize', () => {
            const canvas = document.getElementById('canvas');
            if (canvas) {
                canvas.width = canvas.clientWidth;
                canvas.height = canvas.clientHeight;
            }
        });
        
        // Start the application
        initializeApplication();
    </script>
    
    <!-- Clipboard notification element -->
    <div class="clipboard-notification" id="clipboard-notification">
        <span class="clipboard-notification-icon"></span>
        <span>Copied to your clipboard</span>
    </div>

    <!-- Include the code-blocks.js script -->
    <script src="code-blocks.js"></script>
</body>
</html> 